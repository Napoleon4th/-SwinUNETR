import os
import gzip
import shutil
import json
from pathlib import Path
from tqdm import tqdm
import nibabel as nib
import numpy as np


def reorganize_and_compress_brats_data(input_dir, output_dir=None, delete_original=False, verify_integrity=True):
    """
    é‡æ–°ç»„ç»‡å¹¶å‹ç¼©BrATS21æ•°æ®é›†ï¼ˆæ”¯æŒæ··åˆç»“æ„ï¼Œå¤„ç†kaggleä¸‹è½½çš„æ•°æ®ï¼‰

    æ”¯æŒä¸¤ç§ç»“æ„ï¼š
    1. åµŒå¥—ç»“æ„ï¼š
        BraTS2021_00006/BraTS2021_00006_seg.nii/00000116_final_seg.nii
    2. æ‰å¹³ç»“æ„ï¼š
        BraTS2021_00006/BraTS2021_00006_seg.nii
    è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼ï¼š
        BraTS2021_00006/BraTS2021_00006_seg.nii.gz

    å‚æ•°:
        input_dir: è¾“å…¥ç›®å½•
        output_dir: è¾“å‡ºç›®å½• (Noneè¡¨ç¤ºåœ¨åŸç›®å½•å¤„ç†)
        delete_original: æ˜¯å¦åˆ é™¤åŸå§‹æ–‡ä»¶
        verify_integrity: æ˜¯å¦éªŒè¯æ–‡ä»¶å®Œæ•´æ€§

    è¿”å›:
        å¤„ç†ç»“æœç»Ÿè®¡
    """
    input_dir = Path(input_dir)

    # å¦‚æœæœªæŒ‡å®šè¾“å‡ºç›®å½•ï¼Œåˆ™åœ¨åŸç›®å½•å¤„ç†
    if output_dir is None:
        output_dir = input_dir
    else:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_cases': 0,
        'processed_files': 0,
        'skipped_files': 0,
        'errors': [],
        'file_mapping': {},
        'structure_types': {
            'nested': 0,  # æœ‰å­æ–‡ä»¶å¤¹åµŒå¥—çš„
            'flat': 0,  # ç›´æ¥çš„.niiæ–‡ä»¶
            'mixed': 0,  # æ··åˆçš„
            'invalid': 0  # æ— æ•ˆçš„
        }
    }

    print(f"å¼€å§‹å¤„ç†ç›®å½•: {input_dir}")
    print("=" * 60)

    # è·å–æ‰€æœ‰ç—…ä¾‹æ–‡ä»¶å¤¹
    case_folders = []
    for item in input_dir.iterdir():
        if item.is_dir() and item.name.startswith("BraTS2021_"):
            case_folders.append(item)

    stats['total_cases'] = len(case_folders)
    print(f"æ‰¾åˆ° {len(case_folders)} ä¸ªç—…ä¾‹æ–‡ä»¶å¤¹")

    # å¤„ç†æ¯ä¸ªç—…ä¾‹
    for case_folder in tqdm(case_folders, desc="å¤„ç†ç—…ä¾‹"):
        case_id = case_folder.name
        case_output_dir = output_dir / case_id
        case_output_dir.mkdir(parents=True, exist_ok=True)

        # æ‰«æç—…ä¾‹æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰é¡¹ç›®
        for item in case_folder.iterdir():
            process_item(item, case_output_dir, stats, delete_original, verify_integrity)

    return stats


def process_item(item, case_output_dir, stats, delete_original, verify_integrity):
    """
    å¤„ç†å•ä¸ªé¡¹ç›®ï¼ˆæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ï¼‰

    å‚æ•°:
        item: è¦å¤„ç†çš„é¡¹ç›®ï¼ˆPathå¯¹è±¡ï¼‰
        case_output_dir: è¾“å‡ºç›®å½•
        stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        delete_original: æ˜¯å¦åˆ é™¤åŸå§‹æ–‡ä»¶
        verify_integrity: æ˜¯å¦éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
    """
    try:
        # æƒ…å†µ1: å¦‚æœæ˜¯ä»¥.niiç»“å°¾çš„æ–‡ä»¶å¤¹ï¼ˆåµŒå¥—ç»“æ„ï¼‰
        if item.is_dir() and item.name.endswith('.nii'):
            stats['structure_types']['nested'] += 1
            process_nested_nii_folder(item, case_output_dir, stats, delete_original, verify_integrity)

        # æƒ…å†µ2: å¦‚æœæ˜¯ç›´æ¥çš„.niiæ–‡ä»¶ï¼ˆæ‰å¹³ç»“æ„ï¼‰
        elif item.is_file() and item.name.endswith('.nii'):
            stats['structure_types']['flat'] += 1
            process_flat_nii_file(item, case_output_dir, stats, delete_original, verify_integrity)

        # æƒ…å†µ3: å¦‚æœæ˜¯ä»¥.nii.gzç»“å°¾çš„æ–‡ä»¶ï¼ˆå·²å‹ç¼©ï¼Œè·³è¿‡ï¼‰
        elif item.is_file() and item.name.endswith('.nii.gz'):
            print(f"  â­ï¸  å·²å‹ç¼©ï¼Œè·³è¿‡: {item.name}")
            return

        # æƒ…å†µ4: å…¶ä»–æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹
        elif item.is_dir():
            # å¯èƒ½æ˜¯æ·±å±‚ç»“æ„ï¼Œé€’å½’æ‰«æ
            for sub_item in item.iterdir():
                process_item(sub_item, case_output_dir, stats, delete_original, verify_integrity)
            stats['structure_types']['mixed'] += 1

    except Exception as e:
        error_msg = f"å¤„ç†å¤±è´¥ {item}: {str(e)}"
        stats['errors'].append(error_msg)
        stats['skipped_files'] += 1
        print(f"\nâš ï¸  {error_msg}")


def process_nested_nii_folder(nii_folder, case_output_dir, stats, delete_original, verify_integrity):
    """
    å¤„ç†åµŒå¥—çš„.niiæ–‡ä»¶å¤¹ç»“æ„

    å‚æ•°:
        nii_folder: .niiæ–‡ä»¶å¤¹è·¯å¾„
        case_output_dir: è¾“å‡ºç›®å½•
        stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        delete_original: æ˜¯å¦åˆ é™¤åŸå§‹æ–‡ä»¶
        verify_integrity: æ˜¯å¦éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
    """
    # ç›®æ ‡æ–‡ä»¶å
    target_filename_base = nii_folder.name  # ä¾‹å¦‚BraTS2021_00006_seg.nii
    final_filename = target_filename_base + '.gz'  # ä¾‹å¦‚BraTS2021_00006_seg.nii.gz

    # åœ¨.niiæ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾.niiæ–‡ä»¶
    nii_files = []

    # ä¼˜å…ˆæŸ¥æ‰¾finalæ–‡ä»¶
    nii_files = list(nii_folder.glob("*final*.nii"))

    if not nii_files:
        # æŸ¥æ‰¾æ‰€æœ‰.niiæ–‡ä»¶
        nii_files = list(nii_folder.glob("*.nii"))

    if not nii_files:
        # å¦‚æœè¿˜æ²¡æœ‰ï¼Œå¯èƒ½åœ¨æ›´æ·±å±‚çš„å­æ–‡ä»¶å¤¹ä¸­
        for sub_item in nii_folder.rglob("*.nii"):
            nii_files.append(sub_item)

    if nii_files:
        # å–ç¬¬ä¸€ä¸ª.niiæ–‡ä»¶
        source_file = nii_files[0]
        target_file = case_output_dir / final_filename

        process_single_nii_file(
            source_file, target_file, nii_folder, stats,
            delete_original, verify_integrity, is_nested=True
        )
    else:
        stats['skipped_files'] += 1
        print(f"\nâš ï¸  æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°.niiæ–‡ä»¶: {nii_folder}")


def process_flat_nii_file(nii_file, case_output_dir, stats, delete_original, verify_integrity):
    """
    å¤„ç†æ‰å¹³çš„.niiæ–‡ä»¶

    å‚æ•°:
        nii_file: .niiæ–‡ä»¶è·¯å¾„
        case_output_dir: è¾“å‡ºç›®å½•
        stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        delete_original: æ˜¯å¦åˆ é™¤åŸå§‹æ–‡ä»¶
        verify_integrity: æ˜¯å¦éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
    """
    # ç›®æ ‡æ–‡ä»¶å
    target_filename = nii_file.name + '.gz'  # BraTS2021_00006_seg.nii.gz
    target_file = case_output_dir / target_filename

    process_single_nii_file(
        nii_file, target_file, nii_file.parent, stats,
        delete_original, verify_integrity, is_nested=False
    )


def process_single_nii_file(source_file, target_file, original_parent, stats,
                            delete_original, verify_integrity, is_nested=False):
    """
    å¤„ç†å•ä¸ª.niiæ–‡ä»¶

    å‚æ•°:
        source_file: æºæ–‡ä»¶è·¯å¾„
        target_file: ç›®æ ‡æ–‡ä»¶è·¯å¾„
        original_parent: åŸå§‹çˆ¶ç›®å½•ï¼ˆç”¨äºåˆ é™¤ï¼‰
        stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        delete_original: æ˜¯å¦åˆ é™¤åŸå§‹æ–‡ä»¶
        verify_integrity: æ˜¯å¦éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
        is_nested: æ˜¯å¦æ¥è‡ªåµŒå¥—ç»“æ„
    """
    try:
        # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if target_file.exists():
            print(f"  â­ï¸  ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {target_file.name}")
            return

        # 1. éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
        if verify_integrity:
            try:
                img = nib.load(str(source_file))
                data = img.get_fdata()
                stats['file_mapping'][str(source_file)] = {
                    'target': str(target_file),
                    'shape': data.shape,
                    'dtype': str(data.dtype),
                    'affine': img.affine.tolist(),
                    'is_nested': is_nested
                }
            except Exception as e:
                stats['errors'].append(f"éªŒè¯å¤±è´¥ {source_file}: {str(e)}")
                stats['skipped_files'] += 1
                return

        # 2. å‹ç¼©æ–‡ä»¶
        compress_nii_file(source_file, target_file)

        stats['processed_files'] += 1

        # 3. å¯é€‰æ‹©ï¼šåˆ é™¤åŸå§‹æ–‡ä»¶
        if delete_original:
            # åˆ é™¤æºæ–‡ä»¶
            source_file.unlink()

            # å¦‚æœæ˜¯åµŒå¥—ç»“æ„ï¼Œå°è¯•åˆ é™¤çˆ¶æ–‡ä»¶å¤¹
            if is_nested:
                try:
                    original_parent.rmdir()  # åˆ é™¤.niiæ–‡ä»¶å¤¹
                except:
                    pass  # æ–‡ä»¶å¤¹éç©ºï¼Œä¸åˆ é™¤

    except Exception as e:
        error_msg = f"å¤„ç†å¤±è´¥ {source_file} -> {target_file}: {str(e)}"
        stats['errors'].append(error_msg)
        stats['skipped_files'] += 1
        print(f"\nâš ï¸  {error_msg}")


def compress_nii_file(source_path, target_path):
    """
    å‹ç¼©NIfTIæ–‡ä»¶ä¸º.gzæ ¼å¼

    å‚æ•°:
        source_path: æºæ–‡ä»¶è·¯å¾„
        target_path: ç›®æ ‡æ–‡ä»¶è·¯å¾„ (.nii.gz)
    """
    source_path = Path(source_path)
    target_path = Path(target_path)

    # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
    target_path.parent.mkdir(parents=True, exist_ok=True)

    # ä½¿ç”¨gzipå‹ç¼©
    with open(source_path, 'rb') as f_in:
        with gzip.open(target_path, 'wb') as f_out:
            shutil.copyfileobj(f_in, f_out, length=16 * 1024 * 1024)  # 16MB chunks

    # éªŒè¯å‹ç¼©æ–‡ä»¶
    verify_compressed_file(source_path, target_path)

    return target_path


def verify_compressed_file(original_path, compressed_path):
    """
    éªŒè¯å‹ç¼©æ–‡ä»¶

    å‚æ•°:
        original_path: åŸå§‹æ–‡ä»¶è·¯å¾„
        compressed_path: å‹ç¼©æ–‡ä»¶è·¯å¾„
    """
    original_size = original_path.stat().st_size
    compressed_size = compressed_path.stat().st_size

    # éªŒè¯å‹ç¼©æ–‡ä»¶å¯ä»¥æ­£ç¡®åŠ è½½
    try:
        img = nib.load(str(compressed_path))
        data = img.get_fdata()

        compression_ratio = compressed_size / original_size * 100 if original_size > 0 else 0

        print(f"  âœ“ å‹ç¼©æˆåŠŸ: {original_path.name}")
        print(f"     å›¾åƒå½¢çŠ¶: {data.shape}")

        return True
    except Exception as e:
        print(f"  âœ— éªŒè¯å¤±è´¥: {compressed_path} - {str(e)}")
        # åˆ é™¤æ— æ•ˆçš„å‹ç¼©æ–‡ä»¶
        compressed_path.unlink(missing_ok=True)
        raise e


def format_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.2f} TB"


def analyze_directory_structure(input_dir):
    """
    åˆ†æç›®å½•ç»“æ„ï¼Œè¯†åˆ«ä¸åŒç±»å‹çš„æ–‡ä»¶ç»„ç»‡æ–¹å¼

    å‚æ•°:
        input_dir: è¾“å…¥ç›®å½•
    """
    input_dir = Path(input_dir)

    print("\nğŸ” åˆ†æç›®å½•ç»“æ„...")
    print("=" * 60)

    structure_stats = {
        'nested_folders': [],  # æœ‰.niiæ–‡ä»¶å¤¹çš„
        'flat_files': [],  # æœ‰ç›´æ¥.niiæ–‡ä»¶çš„
        'mixed_cases': [],  # æ··åˆç»“æ„çš„
        'compressed_files': [],  # å·²æœ‰.gzæ–‡ä»¶çš„
        'other_files': []  # å…¶ä»–æ–‡ä»¶
    }

    # è·å–æ‰€æœ‰ç—…ä¾‹æ–‡ä»¶å¤¹
    case_folders = []
    for item in input_dir.iterdir():
        if item.is_dir() and item.name.startswith("BraTS2021_"):
            case_folders.append(item)

    print(f"æ‰¾åˆ° {len(case_folders)} ä¸ªç—…ä¾‹æ–‡ä»¶å¤¹")

    # åˆ†ææ¯ä¸ªç—…ä¾‹
    for case_folder in case_folders[:5]:
        print(f"\nåˆ†æ: {case_folder.name}")

        nested_items = []
        flat_items = []
        compressed_items = []

        for item in case_folder.iterdir():
            if item.is_dir() and item.name.endswith('.nii'):
                nested_items.append(item.name)
            elif item.is_file() and item.name.endswith('.nii'):
                flat_items.append(item.name)
            elif item.is_file() and item.name.endswith('.nii.gz'):
                compressed_items.append(item.name)

        if nested_items and flat_items:
            structure_stats['mixed_cases'].append(case_folder.name)
            print(f"  âš ï¸  æ··åˆç»“æ„: {len(nested_items)}ä¸ªæ–‡ä»¶å¤¹ + {len(flat_items)}ä¸ªæ–‡ä»¶")
        elif nested_items:
            structure_stats['nested_folders'].append(case_folder.name)
            print(f"  ğŸ“ åµŒå¥—ç»“æ„: {len(nested_items)}ä¸ªæ–‡ä»¶å¤¹")
        elif flat_items:
            structure_stats['flat_files'].append(case_folder.name)
            print(f"  ğŸ“„ æ‰å¹³ç»“æ„: {len(flat_items)}ä¸ªæ–‡ä»¶")

        if compressed_items:
            print(f"  â­ï¸  å·²å‹ç¼©: {len(compressed_items)}ä¸ª.gzæ–‡ä»¶")

    # æ‰“å°ç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ“Š ç»“æ„åˆ†æç»Ÿè®¡:")
    print(f"  åµŒå¥—ç»“æ„ç—…ä¾‹: {len(structure_stats['nested_folders'])}")
    print(f"  æ‰å¹³ç»“æ„ç—…ä¾‹: {len(structure_stats['flat_files'])}")
    print(f"  æ··åˆç»“æ„ç—…ä¾‹: {len(structure_stats['mixed_cases'])}")
    print(f"  å·²æœ‰å‹ç¼©æ–‡ä»¶: {len(structure_stats['compressed_files'])}")

    return structure_stats


def save_statistics(stats, output_dir):
    """ä¿å­˜å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
    output_dir = Path(output_dir)

    # ä¿å­˜ç»Ÿè®¡åœ¨jsonæ–‡ä»¶
    stats_path = output_dir / "processing_stats.json"
    with open(stats_path, 'w', encoding='utf-8') as f:
        # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
        json_stats = stats.copy()
        json_stats['file_mapping'] = {
            k: v for k, v in json_stats['file_mapping'].items()
        }
        json.dump(json_stats, f, indent=2, ensure_ascii=False)

    # ä¿å­˜å¤„ç†æŠ¥å‘Š
    report_path = output_dir / "processing_report.txt"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("=" * 60 + "\n")
        f.write("BrATSæ•°æ®å¤„ç†æŠ¥å‘Š\n")
        f.write("=" * 60 + "\n\n")

        f.write(f"å¤„ç†æ—¶é—´: {stats.get('timestamp', 'N/A')}\n")
        f.write(f"è¾“å…¥ç›®å½•: {stats.get('input_dir', 'N/A')}\n")
        f.write(f"è¾“å‡ºç›®å½•: {stats.get('output_dir', 'N/A')}\n\n")

        f.write("-" * 60 + "\n")
        f.write("å¤„ç†ç»Ÿè®¡\n")
        f.write("-" * 60 + "\n")
        f.write(f"æ€»ç—…ä¾‹æ•°: {stats['total_cases']}\n")
        f.write(f"æˆåŠŸå¤„ç†: {stats['processed_files']}\n")
        f.write(f"è·³è¿‡æ–‡ä»¶: {stats['skipped_files']}\n")
        f.write(f"é”™è¯¯æ•°é‡: {len(stats['errors'])}\n\n")

        f.write("-" * 60 + "\n")
        f.write("ç»“æ„ç±»å‹ç»Ÿè®¡\n")
        f.write("-" * 60 + "\n")
        f.write(f"åµŒå¥—ç»“æ„: {stats['structure_types']['nested']}\n")
        f.write(f"æ‰å¹³ç»“æ„: {stats['structure_types']['flat']}\n")
        f.write(f"æ··åˆç»“æ„: {stats['structure_types']['mixed']}\n")
        f.write(f"æ— æ•ˆç»“æ„: {stats['structure_types']['invalid']}\n\n")

        if stats['errors']:
            f.write("-" * 60 + "\n")
            f.write("é”™è¯¯åˆ—è¡¨\n")
            f.write("-" * 60 + "\n")
            for i, error in enumerate(stats['errors'], 1):
                f.write(f"{i:3d}. {error}\n")

    return stats_path, report_path


def smart_reorganize_brats_data(input_dir, output_dir=None, delete_original=False, verify_integrity=True):
    """
    é‡æ–°ç»„ç»‡BrATSæ•°æ®ï¼ˆä¸»å‡½æ•°ï¼‰

    å‚æ•°:
        input_dir: è¾“å…¥ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        delete_original: æ˜¯å¦åˆ é™¤åŸå§‹æ–‡ä»¶
        verify_integrity: æ˜¯å¦éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
    """
    print("=" * 60)
    print("BrATSæ•°æ®é‡ç»„å·¥å…·")
    print("=" * 60)

    # 1. å…ˆåˆ†æç›®å½•ç»“æ„
    structure_stats = analyze_directory_structure(input_dir)

    # 2. è¯¢é—®ç”¨æˆ·ç¡®è®¤
    print("\nå°†ç»Ÿä¸€è½¬æ¢ä¸º:")
    print("   BraTS2021_XXXXX/BraTS2021_XXXXX_xxx.nii.gz")

    response = input("\næ˜¯å¦ç»§ç»­å¤„ç†? (y/n): ").strip().lower()
    if response != 'y':
        print("æ“ä½œå·²å–æ¶ˆ")
        return None

    # 3. æ‰§è¡Œå¤„ç†
    stats = reorganize_and_compress_brats_data(
        input_dir=input_dir,
        output_dir=output_dir,
        delete_original=delete_original,
        verify_integrity=verify_integrity
    )

    return stats


def main():
    """ä¸»å‡½æ•°"""
    import time
    from datetime import datetime

    # é…ç½®å‚æ•°
    input_directory = r"~" # æ•°æ®æ–‡ä»¶å¤¹ï¼Œæœ¬äººç”µè„‘ä¸­ä¸º "E:\æ•°æ®é›†\Data\TrainingData"ï¼Œå³åµŒå¥—ï¼Œæ‰å¹³ç»“æ„çš„ä¸Šä¸€çº§æ–‡ä»¶å¤¹
    output_directory = None  # Noneè¡¨ç¤ºåœ¨åŸç›®å½•å¤„ç†
    delete_original = False
    verify_integrity = True  # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§

    print("BrATSæ•°æ®é‡ç»„å’Œå‹ç¼©å·¥å…·")
    print("=" * 60)
    print(f"è¾“å…¥ç›®å½•: {input_directory}")
    print(f"è¾“å‡ºç›®å½•: {output_directory if output_directory else 'åŸç›®å½•'}")
    print(f"åˆ é™¤åŸå§‹æ–‡ä»¶: {'æ˜¯' if delete_original else 'å¦'}")
    print(f"éªŒè¯æ–‡ä»¶å®Œæ•´æ€§: {'æ˜¯' if verify_integrity else 'å¦'}")
    print("=" * 60)

    # ç¡®è®¤æ“ä½œ
    if delete_original:
        confirmation = input("\nâš ï¸  è­¦å‘Šï¼šè¿™å°†åˆ é™¤åŸå§‹æ–‡ä»¶ï¼ç¡®è®¤ç»§ç»­ï¼Ÿ(yes/no): ")
        if confirmation.lower() != 'yes':
            print("æ“ä½œå·²å–æ¶ˆ")
            return

    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()

    try:
        # æ™ºèƒ½å¤„ç†
        stats = smart_reorganize_brats_data(
            input_dir=input_directory,
            output_dir=output_directory,
            delete_original=delete_original,
            verify_integrity=verify_integrity
        )

        if stats is None:
            return 0

        # æ·»åŠ å…ƒæ•°æ®
        stats['timestamp'] = datetime.now().isoformat()
        stats['input_dir'] = str(input_directory)
        stats['output_dir'] = str(output_directory if output_directory else input_directory)

        # è®¡ç®—è€—æ—¶
        elapsed_time = time.time() - start_time
        stats['elapsed_time'] = elapsed_time

        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        output_dir = Path(output_directory if output_directory else input_directory)
        stats_path, report_path = save_statistics(stats, output_dir)

        # æ‰“å°æŠ¥å‘Š
        print("\n" + "=" * 60)
        print("å¤„ç†å®Œæˆï¼")
        print("=" * 60)
        print(f"æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
        print(f"æ€»ç—…ä¾‹æ•°: {stats['total_cases']}")
        print(f"æˆåŠŸå¤„ç†: {stats['processed_files']} ä¸ªæ–‡ä»¶")
        print(f"è·³è¿‡æ–‡ä»¶: {stats['skipped_files']}")
        print(f"é”™è¯¯æ•°é‡: {len(stats['errors'])}")

        print("\nç»“æ„ç±»å‹ç»Ÿè®¡:")
        print(f"  åµŒå¥—ç»“æ„: {stats['structure_types']['nested']}")
        print(f"  æ‰å¹³ç»“æ„: {stats['structure_types']['flat']}")
        print(f"  æ··åˆç»“æ„: {stats['structure_types']['mixed']}")

        if stats['errors']:
            print(f"\næœ‰ {len(stats['errors'])} ä¸ªé”™è¯¯:")
            for i, error in enumerate(stats['errors'][:5], 1):  # æ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                print(f"  {i}. {error}")
            if len(stats['errors']) > 5:
                print(f"  ... è¿˜æœ‰ {len(stats['errors']) - 5} ä¸ªé”™è¯¯")

        print(f"\nç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_path}")
        print(f"å¤„ç†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

        # æ˜¾ç¤ºä¸€äº›è½¬æ¢ç¤ºä¾‹
        if stats['file_mapping']:
            print(f"\nè½¬æ¢ç¤ºä¾‹:")
            examples = list(stats['file_mapping'].items())[:3]
            for i, (src, info) in enumerate(examples, 1):
                src_name = Path(src).name
                target_name = Path(info['target']).name
                structure_type = "åµŒå¥—" if info.get('is_nested', False) else "æ‰å¹³"
                print(f"  {i}. [{structure_type}] {src_name} -> {target_name}")
                print(f"     å½¢çŠ¶: {info['shape']}")

        # æä¾›æ¸…ç†å»ºè®®
        if not delete_original and stats['processed_files'] > 0:
            print("\næ¸…ç†å»ºè®®:")
            print(f"  å·²å¤„ç† {stats['processed_files']} ä¸ªæ–‡ä»¶ï¼ŒåŸå§‹æ–‡ä»¶ä»ä¿ç•™")
            print(f"  å¦‚éœ€æ¸…ç†ï¼Œå¯è¿è¡Œ: python script.py --input '{input_directory}' --delete")

    except Exception as e:
        print(f"\nå¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


def quick_convert_mode():
    """å¿«é€Ÿè½¬æ¢ï¼ˆä¸éªŒè¯ï¼Œç›´æ¥å‹ç¼©ï¼‰"""
    input_directory = r"E:\æ•°æ®é›†\Data\TrainingData"

    print("å¿«é€Ÿè½¬æ¢æ¨¡å¼")
    print("æ³¨æ„ï¼šæ­¤æ¨¡å¼ä¸éªŒè¯æ–‡ä»¶å®Œæ•´æ€§ï¼Œç›´æ¥å‹ç¼©")
    print(f"å¤„ç†ç›®å½•: {input_directory}")

    stats = {
        'processed': 0,
        'skipped': 0,
        'errors': []
    }

    for root, dirs, files in os.walk(input_directory):
        for item_name in dirs + files:
            item_path = Path(root) / item_name

            # å¤„ç†.niiæ–‡ä»¶å¤¹
            if item_path.is_dir() and item_name.endswith('.nii'):
                process_nii_folder_quick(item_path, stats)

            # å¤„ç†.niiæ–‡ä»¶
            elif item_path.is_file() and item_name.endswith('.nii'):
                process_nii_file_quick(item_path, stats)

    print(f"\nå¿«é€Ÿè½¬æ¢å®Œæˆ!")
    print(f"  æˆåŠŸå¤„ç†: {stats['processed']}")
    print(f"  è·³è¿‡: {stats['skipped']}")
    print(f"  é”™è¯¯: {len(stats['errors'])}")


def process_nii_folder_quick(nii_folder, stats):
    """å¿«é€Ÿå¤„ç†.niiæ–‡ä»¶å¤¹"""
    # æŸ¥æ‰¾.niiæ–‡ä»¶
    nii_files = list(nii_folder.rglob("*.nii"))
    if nii_files:
        source_file = nii_files[0]
        target_file = nii_folder.parent / (nii_folder.name + ".gz")

        try:
            with open(source_file, 'rb') as f_in:
                with gzip.open(target_file, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)

            stats['processed'] += 1
            print(f"âœ“ åµŒå¥—: {source_file.name} -> {target_file.name}")

        except Exception as e:
            stats['errors'].append(str(e))


def process_nii_file_quick(nii_file, stats):
    """å¿«é€Ÿå¤„ç†.niiæ–‡ä»¶"""
    target_file = nii_file.parent / (nii_file.name + ".gz")

    if target_file.exists():
        stats['skipped'] += 1
        return

    try:
        with open(nii_file, 'rb') as f_in:
            with gzip.open(target_file, 'wb') as f_out:
                shutil.copyfileobj(f_in, f_out)

        stats['processed'] += 1
        print(f"âœ“ æ‰å¹³: {nii_file.name} -> {target_file.name}")

    except Exception as e:
        stats['errors'].append(str(e))


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='æ™ºèƒ½é‡ç»„å’Œå‹ç¼©BrATSæ•°æ®')
    parser.add_argument('--input', '-i', default=r"E:\æ•°æ®é›†\Data\TrainingData",
                        help='è¾“å…¥ç›®å½•è·¯å¾„')
    parser.add_argument('--output', '-o', default=None,
                        help='è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ï¼šåŸç›®å½•ï¼‰')
    parser.add_argument('--delete', '-d', action='store_true',
                        help='åˆ é™¤åŸå§‹æ–‡ä»¶')
    parser.add_argument('--quick', '-q', action='store_true',
                        help='å¿«é€Ÿæ¨¡å¼ï¼ˆä¸éªŒè¯ï¼‰')
    parser.add_argument('--analyze', '-a', action='store_true',
                        help='åªåˆ†æç›®å½•ç»“æ„ï¼Œä¸å¤„ç†')

    args = parser.parse_args()

    if args.analyze:
        analyze_directory_structure(args.input)
    elif args.quick:
        quick_convert_mode()
    else:
        # è¿è¡Œä¸»ç¨‹åº
        main()